---
layout: post
title: "Toxic Comment Detector"
categories:
  - Project
tags:
  - Jupyter Notebook
  - scikit learn
---

## Overview

The first non-practice Kaggle competition I've attempted. The results didn't compare especially well to others, but I did learn a few more tricks.


## The Data

[Wikipedia Logs](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge): Around ~96,000 comments from various sections of Wikipedia.

[YouTube Data](https://www.kaggle.com/datasnaek/youtube): A supplemental chunk of data from the dredges of YouTube comments. 

## The Highlights

* An organized machine learning project that generates several features and tests their efficacy in several models. 

* Places an emphasis on Natural Language Processing tools, such as tokenizers, sentiment analysis, and specialized stemming for an internet comment context.

* Utilizes a systematic cross validation approach to tune hyperparameters, optimize feature selection, and display the resulting selections in an easy-to-read manner.

## The Details

The full code can be found [here](https://github.com/justinrgarrard/KaggleToxicComment). 